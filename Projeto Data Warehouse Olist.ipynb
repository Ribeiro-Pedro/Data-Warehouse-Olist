{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b806d7b8",
   "metadata": {},
   "source": [
    "<h1> Projeto Data Warehouse Olist </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad557c8",
   "metadata": {},
   "source": [
    "<h2>Introdução</h2>\n",
    "\n",
    "<p>\n",
    "Este projeto tem como objetivo a construção de um data warehouse com base em um banco de dados relacional e comparar  as diferentes abordagens de modelagem de dados. Os dados utilizados são do dataset de e-commerce disponibilizado pela Olist no Kaggle e pode ser acessado através deste <a href='https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce?datasetId=55151&sortBy=voteCount&sort=votes&select=olist_geolocation_dataset.csv'>link</a>. A modelagem do banco relacional seguiu a proposta disponibilizada no Kaggle, conforme abaixo:</a>\n",
    "</p>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d6814f5",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"screenshots/modelo_relacional.png\" width=\"700\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039b7c1d",
   "metadata": {},
   "source": [
    "<p>\n",
    "    A partir dos arquivos CSV foi construido um ETL para a construção de um banco de dados relacional utilizando o script em Python descrito abaixo. Estabelecendo conexão com o SQL Server, foram criadas as tabelas com as devidas chaves primárias e estrangeiras , posteriormente, o tratamento de valores nulos e carregamento dos dados.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "    Com o banco relacional criado, foi utilizada a ferramenta on-premise SQL Server Service Integration (SSIS) para a criação do ETL do data warehouse consumindo dados do banco de dados recém criado. O modelo lógico do data warehouse é descrito na imagem abaixo: \n",
    "</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c06bec1",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <img src=\"screenshots/modelo_dimensional.jpg\" width=\"600\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957f6b9f",
   "metadata": {},
   "source": [
    "<p>\n",
    "    Após a implementação dos dois bancos com diferentes abordagem de modelagem, mediu-se a performance de consulta para um determidado indicador e verificou-se a melhor performance do modelo dimensional conforme diretrizes propostas por Ralph Kimball em seu livro <a href='https://www.amazon.com.br/Data-Warehouse-Toolkit-Definitive-Dimensional-ebook/dp/B00DRZX6XS/ref=sr_1_1?qid=1668083125&refinements=p_27%3ARalph+Kimball&s=books&sr=1-1&ufe=app_do%3Aamzn1.fos.fcd6d665-32ba-4479-9f21-b774e276a678'>The Data Warehouse Toolkit: The Definitive Guide to Dimensional Modeling</a>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09caa258",
   "metadata": {},
   "source": [
    "<h2>ETL Banco Relacional Olist</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18d3644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulação dos dados\n",
    "import pandas as pd\n",
    "\n",
    "# Tratamento de Strings\n",
    "from unidecode import unidecode\n",
    "\n",
    "# Tratamento de dados do tipo datetime\n",
    "from datetime import datetime\n",
    "\n",
    "# Conexão Python com SQLServer\n",
    "import pyodbc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa75de5d",
   "metadata": {},
   "source": [
    "<h3> Conexão com SQL Server </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbd46e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conexão com o banco de dados on-premise\n",
    "cnxn_str = (\"DRIVER={SQL Server Native Client 11.0};\"\n",
    "            \"SERVER=DESKTOP-0NS6QID;\"\n",
    "            \"DATABASE=RELACIONAL_OLIST;\"\n",
    "            \"UID=sa;\"\n",
    "            \"PWD=**********\")\n",
    "\n",
    "cnxn = pyodbc.connect(cnxn_str)\n",
    "\n",
    "# Criação do cursor para executar os comandos SQL\n",
    "cursor = cnxn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39d9b75",
   "metadata": {},
   "source": [
    "<h3> Tabela Produtos</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37205e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id                      0\n",
       "product_category_name         610\n",
       "product_name_lenght           610\n",
       "product_description_lenght    610\n",
       "product_photos_qty            610\n",
       "product_weight_g                2\n",
       "product_length_cm               2\n",
       "product_height_cm               2\n",
       "product_width_cm                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga dos dados\n",
    "produtos = pd.read_csv(\"data_olist/olist_products_dataset.csv\")\n",
    "\n",
    "# Checagem dos valores nulos\n",
    "produtos.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d0166ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id                      0\n",
       "product_category_name           0\n",
       "product_name_lenght           610\n",
       "product_description_lenght    610\n",
       "product_photos_qty            610\n",
       "product_weight_g                2\n",
       "product_length_cm               2\n",
       "product_height_cm               2\n",
       "product_width_cm                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tratamento dos valores categóricos nulos\n",
    "produtos[\"product_category_name\"] = produtos[\"product_category_name\"].fillna(\"sem categoria\")\n",
    "\n",
    "produtos.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "374dc4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id                    0\n",
       "product_category_name         0\n",
       "product_name_lenght           0\n",
       "product_description_lenght    0\n",
       "product_photos_qty            0\n",
       "product_weight_g              0\n",
       "product_length_cm             0\n",
       "product_height_cm             0\n",
       "product_width_cm              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tratamento dos valores numéricos nulos\n",
    "numericos = [\"product_name_lenght\",\n",
    "             \"product_description_lenght\",\n",
    "             \"product_photos_qty\",\n",
    "             \"product_weight_g\",\n",
    "             \"product_length_cm\",\n",
    "             \"product_height_cm\",\n",
    "             \"product_width_cm\"]\n",
    "\n",
    "produtos[numericos] = produtos[numericos].fillna(0)\n",
    "produtos.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f1604ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação da tabela Produtos no SQL\n",
    "cursor.execute('''\n",
    "                CREATE TABLE [PRODUTOS] (\n",
    "                  [cod_produto] CHAR(32) NOT NULL, \n",
    "                  [categoria] VARCHAR(50) NULL, \n",
    "                  [tamanho_nome] INT NULL, \n",
    "                  [tamanho_descricao] INT NULL, \n",
    "                  [qnt_fotos] INT NULL, \n",
    "                  [massa] INT NULL, \n",
    "                  [comprimento] INT NULL, \n",
    "                  [largura] INT NULL, \n",
    "                  [altura] INT NULL, \n",
    "                  CONSTRAINT [PK_PRODUTOS] PRIMARY KEY CLUSTERED (cod_produto)\n",
    "                );\n",
    "                ''')\n",
    "\n",
    "# Carga dos dados na tabela Produtos\n",
    "for row in produtos.itertuples():\n",
    "    cursor.execute('''INSERT INTO PRODUTOS (\n",
    "                          cod_produto, categoria, tamanho_nome, \n",
    "                          tamanho_descricao, qnt_fotos, massa, \n",
    "                          comprimento, largura, altura\n",
    "                        ) \n",
    "                        VALUES \n",
    "                          (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "\n",
    "                   ''',\n",
    "                   row.product_id, \n",
    "                   row.product_category_name,\n",
    "                   row.product_name_lenght,\n",
    "                   row.product_description_lenght,\n",
    "                   row.product_photos_qty,\n",
    "                   row.product_weight_g,\n",
    "                   row.product_length_cm,\n",
    "                   row.product_width_cm,\n",
    "                   row.product_height_cm\n",
    "                  )\n",
    "    \n",
    "\n",
    "cursor.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58047ff7",
   "metadata": {},
   "source": [
    "<h3> Tabela Avaliações</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c44c526f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_id                      0\n",
       "order_id                       0\n",
       "review_score                   0\n",
       "review_comment_title       87656\n",
       "review_comment_message     58247\n",
       "review_creation_date           0\n",
       "review_answer_timestamp        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga dos dados de avaliação\n",
    "avaliacoes = pd.read_csv(\"data_olist/olist_order_reviews_dataset.csv\", encoding='utf_8')\n",
    "\n",
    "# Checagem dos valores nulos\n",
    "avaliacoes.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65a80272",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_id                  0\n",
       "order_id                   0\n",
       "review_score               0\n",
       "review_comment_title       0\n",
       "review_comment_message     0\n",
       "review_creation_date       0\n",
       "review_answer_timestamp    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Colunas com valores nulos\n",
    "null_columns = ['review_comment_message', 'review_comment_title']\n",
    "\n",
    "# Tratamento dos dados tipo string\n",
    "avaliacoes[null_columns] = avaliacoes[null_columns].fillna(\"sem conteudo\")\n",
    "avaliacoes[\"review_comment_message\"] = avaliacoes[\"review_comment_message\"].apply(lambda x : x.replace(\"\\r\\n\",' '))\n",
    "avaliacoes[\"review_comment_message\"] = avaliacoes[\"review_comment_message\"].apply(lambda x : x.replace(\",\",';'))\n",
    "avaliacoes[\"review_comment_message\"] = avaliacoes[\"review_comment_message\"].apply(lambda x : unidecode(x).lower())\n",
    "avaliacoes[\"review_comment_message\"] = avaliacoes[\"review_comment_message\"].apply(lambda x : x.replace(\"'\",\"\"))\n",
    "avaliacoes[\"review_comment_title\"] = avaliacoes[\"review_comment_title\"].apply(lambda x : unidecode(x).lower())\n",
    "avaliacoes = avaliacoes.groupby('review_id').first().reset_index()\n",
    "\n",
    "# Checagem dos valores nulos\n",
    "avaliacoes.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f4b1d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação da tabela Avaliações\n",
    "cursor.execute('''\n",
    "                CREATE TABLE [AVALIACOES](\n",
    "                    [cod_avaliacao] CHAR(32) NOT NULL,\n",
    "                    [cod_pedido] CHAR(32) NULL,\n",
    "                    [pontuacao] INT NULL,\n",
    "                    [titulo_comentario] NVARCHAR(100) NULL,\n",
    "                    [mensagem_comentario] NVARCHAR(500) NULL,\n",
    "                    [data_criacao] SMALLDATETIME NULL,\n",
    "                    [data_resposta] SMALLDATETIME NULL,\n",
    "                    CONSTRAINT [PK_AVALIACOES] PRIMARY KEY CLUSTERED (cod_avaliacao)\n",
    "                );\n",
    "                ''')\n",
    "\n",
    "# Carga dos dados na tabela Avaliações\n",
    "for row in avaliacoes.itertuples():\n",
    "    cursor.execute('''INSERT INTO AVALIACOES\n",
    "                          (cod_avaliacao,cod_pedido,pontuacao,titulo_comentario,\n",
    "                          mensagem_comentario,data_criacao,data_resposta)   \n",
    "                      VALUES(?,?,?,?,?,?,?)\n",
    "                   ''',\n",
    "                   row.review_id, \n",
    "                   row.order_id,\n",
    "                   row.review_score,\n",
    "                   row.review_comment_title,\n",
    "                   row.review_comment_message,\n",
    "                   row.review_creation_date,\n",
    "                   row.review_answer_timestamp\n",
    "                  )\n",
    "    \n",
    "\n",
    "cursor.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7732a2",
   "metadata": {},
   "source": [
    "<h3> Tabela Clientes </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c2d0dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id                 0\n",
       "customer_unique_id          0\n",
       "customer_zip_code_prefix    0\n",
       "customer_city               0\n",
       "customer_state              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga dos dados de Clientes\n",
    "clientes = pd.read_csv(\"data_olist/olist_customers_dataset.csv\", dtype='str')\n",
    "\n",
    "# Checagem dos valores nulos\n",
    "clientes.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c30ff4ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checagem dos valores de código do cliente duplicados\n",
    "clientes.customer_id.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06ad9688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação da tabela Clientes\n",
    "cursor.execute('''\n",
    "                CREATE TABLE [CLIENTES](\n",
    "                    [cod_cliente_pedido] CHAR(32) NOT NULL,\n",
    "                    [cod_cliente] CHAR(32) NULL,\n",
    "                    [prefix_cep] CHAR(5) NULL,\n",
    "                    [cidade] VARCHAR(50) NULL,\n",
    "                    [estado] VARCHAR(50) NULL,\n",
    "                    CONSTRAINT [PK_CLIENTES] PRIMARY KEY CLUSTERED (cod_cliente_pedido)\n",
    "                );\n",
    "                ''')\n",
    "\n",
    "# Carga dos dados na tabela Clientes\n",
    "for row in clientes.itertuples():\n",
    "    cursor.execute('''INSERT INTO CLIENTES\n",
    "                          (cod_cliente_pedido,\n",
    "                          cod_cliente,\n",
    "                          prefix_cep,\n",
    "                          cidade,\n",
    "                          estado)   \n",
    "                      VALUES(?,?,?,?,?)\n",
    "                   ''',\n",
    "                   row.customer_id, \n",
    "                   row.customer_unique_id,\n",
    "                   row.customer_zip_code_prefix,\n",
    "                   row.customer_city,\n",
    "                   row.customer_state)   \n",
    "\n",
    "cursor.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce134556",
   "metadata": {},
   "source": [
    "<h3> Tabela Geolocalização</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7eda7ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geolocation_zip_code_prefix    0\n",
       "geolocation_lat                0\n",
       "geolocation_lng                0\n",
       "geolocation_state              0\n",
       "geolocation_city               0\n",
       "geometry                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determinação do tipo dos dados de geolocalização\n",
    "types = {'geolocation_zip_code_prefix':'str',\n",
    "         'geolocation_lat': 'float',\n",
    "         'geolocation_lng': 'float',\n",
    "         'geolocation_state': 'str',\n",
    "         'geolocation_city': 'str',\n",
    "         'geometry': 'str'}\n",
    "\n",
    "# Carga dos dados de geolocalização\n",
    "geo = pd.read_csv(\"data_olist/olist_geolocation_dataset_transformed.csv\", dtype=types)\n",
    "\n",
    "# Checagem dos valores nulos\n",
    "geo.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd1e7230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamento dos dados do tipo sting\n",
    "geo['geolocation_state'] = geo['geolocation_state'].apply(lambda x: unidecode(x).lower())\n",
    "geo['geolocation_city'] = geo['geolocation_city'].apply(lambda x: x.replace(\",\", \"\"))\n",
    "geo['geolocation_zip_code_prefix'] = geo['geolocation_zip_code_prefix'].apply(lambda x: x.zfill(5)) \n",
    "\n",
    "# Reorganização da disposisão das colunas\n",
    "geo = geo.set_index(\"geolocation_zip_code_prefix\")\n",
    "geo = geo[['geolocation_lat', 'geolocation_lng', 'geolocation_state','geolocation_city']]\n",
    "geo = geo.groupby('geolocation_zip_code_prefix').first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec4843df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação da tabela Geolocalização\n",
    "cursor.execute('''\n",
    "                CREATE TABLE [GEOLOCALIZACAO](\n",
    "                    [prefix_cep] CHAR(5) NOT NULL,\n",
    "                    [latitude] FLOAT NULL,\n",
    "                    [longitude] FLOAT NULL,\n",
    "                    [cidade] VARCHAR(50) NULL,\n",
    "                    [estado] VARCHAR(50) NULL,\n",
    "                    CONSTRAINT [PK_GEOLOCALIZACAO] PRIMARY KEY CLUSTERED (prefix_cep)\n",
    "                );\n",
    "                ''')\n",
    "\n",
    "# Carga dos dados na tabela Geolocalização\n",
    "for row in geo.itertuples():\n",
    "    cursor.execute('''INSERT INTO GEOLOCALIZACAO\n",
    "                          (prefix_cep,\n",
    "                          latitude,\n",
    "                          longitude,\n",
    "                          cidade,\n",
    "                          estado)   \n",
    "                      VALUES(?,?,?,?,?)\n",
    "                   ''',\n",
    "                   row.geolocation_zip_code_prefix, \n",
    "                   row.geolocation_lat,\n",
    "                   row.geolocation_lng,\n",
    "                   row.geolocation_city,\n",
    "                   row.geolocation_state)\n",
    "\n",
    "# Inserção registros que faltavam de cep dos vendedores\n",
    "cursor.execute('''\n",
    "                INSERT INTO GEOLOCALIZACAO (\n",
    "                  prefix_cep, longitude, latitude, cidade, \n",
    "                  estado\n",
    "                ) \n",
    "                VALUES \n",
    "                  (\n",
    "                    '02285', -46.5678753, -23.431341, \n",
    "                    'sao paulo', 'sp'\n",
    "                  ), \n",
    "                  (\n",
    "                    '07412', -46.341797, -23.3994586, \n",
    "                    'aruja', 'sp'\n",
    "                  ), \n",
    "                  (\n",
    "                    '21941', -43.2438268, -22.8143993, \n",
    "                    'rio de janeiro', 'rj'\n",
    "                  ), \n",
    "                  (\n",
    "                    '37708', -46.4992939, -21.8124775, \n",
    "                    'pocos de caldas', 'mg'\n",
    "                  ), \n",
    "                  (\n",
    "                    '71551', -47.8679859, -15.7045682, \n",
    "                    'brasilia', 'df'\n",
    "                  ), \n",
    "                  (\n",
    "                    '72580', -47.9893173, -15.9924741, \n",
    "                    'brasilia', 'df'\n",
    "                  ), \n",
    "                  (\n",
    "                    '82040', -49.2056041, -25.3981577, \n",
    "                    'curitiba', 'pr'\n",
    "                  ), \n",
    "                  (\n",
    "                    '91901', -51.2589679, -30.1060653, \n",
    "                    'porto alegre', 'rs'\n",
    "                  )\n",
    "                ;\n",
    "              ''')\n",
    "\n",
    "# Inserção dos registros que faltavam do cadastro de clientes\n",
    "cursor.execute('''\n",
    "                INSERT INTO GEOLOCALIZACAO (prefix_cep, cidade, estado) \n",
    "                SELECT \n",
    "                  DISTINCT c.prefix_cep, \n",
    "                  c.cidade, \n",
    "                  c.estado \n",
    "                FROM \n",
    "                  [RELACIONAL_OLIST].[dbo].[CLIENTES] c \n",
    "                  LEFT JOIN [RELACIONAL_OLIST].[dbo].[GEOLOCALIZACAO] geo ON geo.prefix_cep = c.prefix_cep \n",
    "                WHERE \n",
    "                  geo.cidade IS NULL \n",
    "                  AND c.cidade <> 'parati'\n",
    "                ''')\n",
    "    \n",
    "\n",
    "cursor.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669e02fc",
   "metadata": {},
   "source": [
    "<h3> Tabela Vendedores</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b5fcf1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seller_id                 0\n",
       "seller_zip_code_prefix    0\n",
       "seller_city               0\n",
       "seller_state              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga dos dados de Vendedores\n",
    "vendedores = pd.read_csv(\"data_olist/olist_sellers_dataset.csv\", dtype='str')\n",
    "\n",
    "# Checagem dos valores nulos\n",
    "vendedores.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd478985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checagem dos valores de código de vendedore duplicados\n",
    "vendedores.seller_id.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "707e443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação da tabela Vendedores\n",
    "cursor.execute('''\n",
    "                CREATE TABLE [VENDEDORES](\n",
    "                    [cod_vendedor] CHAR(32) NOT NULL,\n",
    "                    [prefix_cep] CHAR(5) NULL,\n",
    "                    [cidade] VARCHAR(50) NULL,\n",
    "                    [estado] CHAR(2) NULL,\n",
    "                    CONSTRAINT [PK_VENDEDORES] PRIMARY KEY CLUSTERED (cod_vendedor)\n",
    "                );\n",
    "                ''')\n",
    "\n",
    "# Carga dos dados na tabela Vendedores\n",
    "for row in vendedores.itertuples():\n",
    "    cursor.execute('''INSERT INTO VENDEDORES\n",
    "                          (cod_vendedor,\n",
    "                          prefix_cep,\n",
    "                          cidade,\n",
    "                          estado)   \n",
    "                      VALUES(?,?,?,?)\n",
    "                   ''',\n",
    "                   row.seller_id, \n",
    "                   row.seller_zip_code_prefix,\n",
    "                   row.seller_city,\n",
    "                   row.seller_state)   \n",
    "\n",
    "cursor.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6bea90",
   "metadata": {},
   "source": [
    "<h3> Tabela Pagamentos</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "761f1d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                0\n",
       "payment_sequential      0\n",
       "payment_type            0\n",
       "payment_installments    0\n",
       "payment_value           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga dos dados de pagamentos\n",
    "pagamentos = pd.read_csv(\"data_olist/olist_order_payments_dataset.csv\")\n",
    "\n",
    "# Checagem dos valores nulos\n",
    "pagamentos.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69a0f46",
   "metadata": {},
   "source": [
    "<p>\n",
    "    A coluna sequencial pagamento delimita quantos tipos de pagamentos foram feitos para cada pedido, por exemplo, se um cliente pagou utilizando cartão de crédito e débito, a tabela pagamento terá registros únicos para cada tipo, diferenciando cada um deles pelo campo payment_sequential. Em alguns casos, existiam pagamentos que se iniciavam com payment_sequential = 2 ou = 3. O script abaixo conserta esta inconsistência nos dados\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bb051b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista dos pagamentos iniciados com payment_sequential = 2\n",
    "list_seq_2 = []\n",
    "\n",
    "# Lista dos pagamentos iniciados com payment_sequential = 3\n",
    "list_seq_3 = []\n",
    "\n",
    "# Iteração entre os registros com payment_sequential = 2\n",
    "for i in pagamentos[pagamentos.payment_sequential == 2].index:\n",
    "    order_id = pagamentos.order_id.loc[i]\n",
    "    # Checagem para determinar se o registro com payment_sequential = 2 era único\n",
    "    if len(pagamentos[pagamentos.order_id == order_id]) == 1:\n",
    "        # Adição à lista de registros com inconsistência\n",
    "        list_seq_2.append(pagamentos[pagamentos.order_id == order_id].index)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# Iteração entre os registros com payment_sequential = 3\n",
    "for i in pagamentos[pagamentos.payment_sequential == 3].index:\n",
    "    order_id = pagamentos.order_id.loc[i]\n",
    "    # Checagem para determinar se o registro com payment_sequential = 3 tinha 3 elementos\n",
    "    if len(pagamentos[pagamentos.order_id == order_id]) == 2:\n",
    "        # Adição à lista de registros com inconsistência\n",
    "        list_seq_3.append(pagamentos[pagamentos.order_id == order_id].index)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# Alteração dos registros conforme regra de negócio\n",
    "for i in list_seq_2:\n",
    "    pagamentos.loc[i,'payment_sequential'] = 1\n",
    "    \n",
    "for i in range(len(list_seq_3)):\n",
    "    seq = 1\n",
    "    for j in list_seq_3[i]:\n",
    "        pagamentos.loc[j,'payment_sequential'] = seq\n",
    "        seq += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42320b99",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checagem dos valores duplicados para a chave primária composta\n",
    "pagamentos[['order_id','payment_sequential']].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b65cdedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação da tabela Pagamentos\n",
    "cursor.execute('''\n",
    "                CREATE TABLE [PAGAMENTOS](\n",
    "                    [cod_pedido] CHAR(32) NOT NULL,\n",
    "                    [sequencial_pagamento] INT NOT NULL,\n",
    "                    [tipo] VARCHAR(50) NULL,\n",
    "                    [parcelas] INT NULL,\n",
    "                    [valor] FLOAT NULL,\n",
    "                    CONSTRAINT [PK_PAGAMENTOS] PRIMARY KEY CLUSTERED (cod_pedido,sequencial_pagamento)\n",
    "                );\n",
    "                ''')\n",
    "\n",
    "# Carga dos dados na tabela Pagamentos\n",
    "for row in pagamentos.itertuples():\n",
    "    cursor.execute('''INSERT INTO PAGAMENTOS\n",
    "                          (cod_pedido,\n",
    "                          sequencial_pagamento,\n",
    "                          tipo,\n",
    "                          parcelas,\n",
    "                          valor)   \n",
    "                      VALUES(?,?,?,?,?)\n",
    "                   ''',\n",
    "                   row.order_id, \n",
    "                   row.payment_sequential,\n",
    "                   row.payment_type,\n",
    "                   row.payment_installments,\n",
    "                   row.payment_value)\n",
    "    \n",
    "# Inserção um registro faltante\n",
    "cursor.execute('''INSERT INTO PAGAMENTOS(\n",
    "                      cod_pedido, sequencial_pagamento, \n",
    "                      valor\n",
    "                    ) \n",
    "                    VALUES \n",
    "                      (\n",
    "                        'bfbd0f9bdef84302105ad712db648a6c', \n",
    "                        1, 134.97\n",
    "                      )\n",
    "                ''')\n",
    "\n",
    "cursor.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602aea59",
   "metadata": {},
   "source": [
    "<h3>Tabela Pedidos</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "64ad3d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                            0\n",
       "customer_id                         0\n",
       "order_status                        0\n",
       "order_purchase_timestamp            0\n",
       "order_approved_at                 160\n",
       "order_delivered_carrier_date     1783\n",
       "order_delivered_customer_date    2965\n",
       "order_estimated_delivery_date       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga dos dados de Pedidos\n",
    "pedidos = pd.read_csv(\"data_olist/olist_orders_dataset.csv\")\n",
    "\n",
    "# Chegagem de valores nulos\n",
    "pedidos.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96cc06e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                         0\n",
       "customer_id                      0\n",
       "order_status                     0\n",
       "order_purchase_timestamp         0\n",
       "order_approved_at                0\n",
       "order_delivered_carrier_date     0\n",
       "order_delivered_customer_date    0\n",
       "order_estimated_delivery_date    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tratamento de valores nulos\n",
    "pedidos = pedidos.fillna(0)\n",
    "\n",
    "# Checagem de valores nulos\n",
    "pedidos.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6976a6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checagem de código de pedido duplicados\n",
    "pedidos.order_id.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f53efffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação da tabela Pedidos\n",
    "cursor.execute('''\n",
    "                CREATE TABLE [PEDIDOS](\n",
    "                    [cod_pedido] CHAR(32) NOT NULL,\n",
    "                    [cod_cliente] CHAR(32) NULL,\n",
    "                    [status] VARCHAR(20) NULL,\n",
    "                    [data] SMALLDATETIME NULL,\n",
    "                    [data_aprovacao] SMALLDATETIME NULL,\n",
    "                    [data_entrega_transportadora] SMALLDATETIME NULL,\n",
    "                    [data_entrega_cliente] SMALLDATETIME NULL,\n",
    "                    [data_estimada_entrega] SMALLDATETIME NULL,\n",
    "                    CONSTRAINT [PK_PEDIDOS] PRIMARY KEY CLUSTERED (cod_pedido)\n",
    "                );\n",
    "                ''')\n",
    "\n",
    "# Carga dos dados na tabela Pedidos\n",
    "for row in pedidos.itertuples():\n",
    "    cursor.execute('''INSERT INTO PEDIDOS\n",
    "                          (cod_pedido,\n",
    "                          cod_cliente,\n",
    "                          status,\n",
    "                          data,\n",
    "                          data_aprovacao,\n",
    "                          data_entrega_transportadora,\n",
    "                          data_entrega_cliente,\n",
    "                          data_estimada_entrega)   \n",
    "                      VALUES(?,?,?,?,?,?,?,?)\n",
    "                   ''',\n",
    "                   row.order_id, \n",
    "                   row.customer_id,\n",
    "                   row.order_status,\n",
    "                   row.order_purchase_timestamp,\n",
    "                   row.order_approved_at,\n",
    "                   row.order_delivered_carrier_date,\n",
    "                   row.order_delivered_customer_date,\n",
    "                   row.order_estimated_delivery_date)   \n",
    "\n",
    "cursor.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7d5ce9",
   "metadata": {},
   "source": [
    "<h3>Tabela Itens Pedidos </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5bb23604",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id               0\n",
       "order_item_id          0\n",
       "product_id             0\n",
       "seller_id              0\n",
       "shipping_limit_date    0\n",
       "price                  0\n",
       "freight_value          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga dos dados de Itens Pedido\n",
    "itens_pedido = pd.read_csv(\"data_olist/olist_order_items_dataset.csv\")\n",
    "\n",
    "# Checagem de valores nulos\n",
    "itens_pedido.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "676b9955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação da tabela de Itens_Pedido\n",
    "cursor.execute('''\n",
    "                CREATE TABLE[ITENS_PEDIDO](\n",
    "                    [cod_pedido] CHAR(32) NOT NULL,\n",
    "                    [item_pedido] INT NOT NULL,\n",
    "                    [cod_produto] CHAR(32) NOT NULL,\n",
    "                    [cod_vendedor] CHAR(32) NOT NULL,\n",
    "                    [data_limite_entrega] SMALLDATETIME NULL,\n",
    "                    [preco] FLOAT NULL,\n",
    "                    [frete] FLOAT NULL,\n",
    "                    CONSTRAINT [PK_ITENS_PEDIDOS] PRIMARY KEY CLUSTERED (cod_pedido,item_pedido)\n",
    "                );\n",
    "                ''')\n",
    "\n",
    "# Carga dos dados na tabela Itens Pedido\n",
    "for row in itens_pedido.itertuples():\n",
    "    cursor.execute('''INSERT INTO ITENS_PEDIDO\n",
    "                          (cod_pedido,\n",
    "                          item_pedido,\n",
    "                          cod_produto,\n",
    "                          cod_vendedor,\n",
    "                          data_limite_entrega,\n",
    "                          preco,\n",
    "                          frete)   \n",
    "                      VALUES(?,?,?,?,?,?,?)\n",
    "                   ''',\n",
    "                   row.order_id, \n",
    "                   row.order_item_id,\n",
    "                   row.product_id,\n",
    "                   row.seller_id,\n",
    "                   row.shipping_limit_date,\n",
    "                   row.price,\n",
    "                   row.freight_value)   \n",
    "\n",
    "cursor.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8398b03b",
   "metadata": {},
   "source": [
    "<h3> Foreign Keys </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b2fb442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação das chaves estrangeiras conforme modelo relacional\n",
    "cursor.execute('''\n",
    "                ALTER TABLE [VENDEDORES] WITH CHECK ADD CONSTRAINT [FK_VENDEDORES_GEOLOCALIZACAO]\n",
    "                FOREIGN KEY ([prefix_cep]) REFERENCES [GEOLOCALIZACAO] ([prefix_cep]);\n",
    "\n",
    "                ALTER TABLE [CLIENTES] WITH CHECK ADD CONSTRAINT [FK_CLIENTES_GEOLOCALIZACAO]\n",
    "                FOREIGN KEY ([prefix_cep]) REFERENCES [GEOLOCALIZACAO] ([prefix_cep]);\n",
    "\n",
    "                ALTER TABLE [PEDIDOS] WITH CHECK ADD CONSTRAINT [FK_PEDIDOS_CLIENTES]\n",
    "                FOREIGN KEY ([cod_cliente]) REFERENCES [CLIENTES] ([cod_cliente_pedido]);\n",
    "\n",
    "                ALTER TABLE [AVALIACOES] WITH CHECK ADD CONSTRAINT [FK_AVALIACOES_PEDIDOS]\n",
    "                FOREIGN KEY ([cod_pedido]) REFERENCES [PEDIDOS] ([cod_pedido]);\n",
    "\n",
    "                ALTER TABLE [PAGAMENTOS] WITH CHECK ADD CONSTRAINT [FK_PAGAMENTOS_PEDIDOS]\n",
    "                FOREIGN KEY ([cod_pedido]) REFERENCES [PEDIDOS] ([cod_pedido]);\n",
    "\n",
    "                ALTER TABLE [ITENS_PEDIDO] WITH CHECK ADD CONSTRAINT [FK_ITENS_PEDIDO_PEDIDOS]\n",
    "                FOREIGN KEY ([cod_pedido]) REFERENCES [PEDIDOS] ([cod_pedido]);\n",
    "\n",
    "                ALTER TABLE [ITENS_PEDIDO] WITH CHECK ADD CONSTRAINT [FK_ITENS_PEDIDO_PRODUTOS]\n",
    "                FOREIGN KEY ([cod_produto]) REFERENCES [PRODUTOS] ([cod_produto]);\n",
    "\n",
    "                ALTER TABLE [ITENS_PEDIDO] WITH CHECK ADD CONSTRAINT [FK_ITENS_PEDIDO_VENDEDORES]\n",
    "                FOREIGN KEY ([cod_vendedor]) REFERENCES [VENDEDORES] ([cod_vendedor]);\n",
    "            ''')\n",
    "\n",
    "cursor.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38754f4e",
   "metadata": {},
   "source": [
    "<h3>Modelo de dados Relacional</h3>\n",
    "<div>\n",
    "    <img src=\"screenshots/modelo_relacional.png\" width=\"700\">   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0378c4",
   "metadata": {},
   "source": [
    "<h2>ETL do data warehouse Olist</h2>\n",
    "\n",
    "<p>\n",
    "   A modelagem do data warehouse foi feita conforme a matriz dimensão-indicador abaixo. Os conceitos foram retirados do livro <a href='https://www.amazon.com.br/Data-Warehouse-Toolkit-Definitive-Dimensional-ebook/dp/B00DRZX6XS/ref=sr_1_1?qid=1668083125&refinements=p_27%3ARalph+Kimball&s=books&sr=1-1&ufe=app_do%3Aamzn1.fos.fcd6d665-32ba-4479-9f21-b774e276a678'>The Data Warehouse Toolkit: The Definitive Guide to Dimensional Modeling</a> de Ralph Kimball.\n",
    "</p>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td> </td>\n",
    "        <td>Cliente</td>\n",
    "        <td>Produto</td>\n",
    "        <td>Pagamento</td>\n",
    "        <td>Vendedor</td>\n",
    "        <td>Tempo</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Unidades vendidas</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Valor da compra</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Custo de Frete</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Data</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Data Aprovação</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Data entrega p/ transportadora</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Data entrega p/ cliente</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Data estimada de entrega</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Status da entrega</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "        <td>x</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<p>\n",
    "   O ETL se divide basicamente entre a criação das tabelas e a carga dos dados. Estes dois processos serão descritos uma única vez, já que a criação de diferentes tabelas e a carga do dados não tem diferenças consideráveis nos processos.    \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d33987",
   "metadata": {},
   "source": [
    "<h3>Criação do Projeto</h3>\n",
    "\n",
    "<table>\n",
    "    <td><img src=\"screenshots/1.jpg\" width=\"250\"/></td>\n",
    "    <td><img src=\"screenshots/2.jpg\" width=\"350\"/></td>\n",
    "</table>\n",
    "    \n",
    "<p>\n",
    "    Clicando com o botão direito do mouse abre-se a janela de propriedades, seleciona-se a versão 2017 do SQL Server e habilita-se a opção que cria um scrip SQL a partir das modificações feitas no projeto.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a54b5b0",
   "metadata": {},
   "source": [
    "<h3>Criação de Tabelas</h3>\n",
    "\n",
    "<table>\n",
    "    <td><img src=\"screenshots/3.jpg\" width=\"400\"/></td>\n",
    "    <td><img src=\"screenshots/3.1.jpg\" width=\"200\"/></td>  \n",
    "    <td><img src=\"screenshots/4.jpg\" width=\"300\"/></td>\n",
    "</table>\n",
    "\n",
    "<p>\n",
    "    Para melhorar a organização, primeiro cria-se uma pasta para acomodar os scripts de criação de tabelas. Depois, clicando com o botão direito do mouse sobre a pasta recém criada, seleciona-se a opção de novo item. Um menu com diversas opções se apresentará e seleciona-se a opção nova tabela.\n",
    "</p>\n",
    "\n",
    "<table>\n",
    "    <td><img src=\"screenshots/5.jpg\" width=\"400\"/></td>\n",
    "    <td><img src=\"screenshots/6.jpg\" width=\"250\"/></td>\n",
    "</table>\n",
    "\n",
    "<p>\n",
    "    Conforme a imagem acima, existe a possibilidade de criar as tabelas através de um assistente low code. Com as alterações cria-se automaticamente um script SQL correspondente. Os scripts utilizados na criação das tabelas podem ser verificados na próxima sessão deste artigo. Após finalizar, clica-se com o botão direito no projeto e na opção rebuild (recompilar) para verificar qualquer erro.\n",
    "</p>\n",
    "\n",
    "<table>\n",
    "    <td><img src=\"screenshots/7.jpg\" width=\"150\"/></td>\n",
    "    <td><img src=\"screenshots/8.jpg\" width=\"400\"/></td>\n",
    "    <td><img src=\"screenshots/9.jpg\" width=\"400\"/></td>\n",
    "</table>\n",
    "\n",
    "<p>\n",
    "    Não havendo nenhum erro após a recompilação, seleciona-se a opção publish (publicar) para aplicar as modificações no banco de dados SQL. Após estabelecer a conexão conforme imagem acima, as modificações já podem ser verificadas no SQL Server Management Studio.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1fd435",
   "metadata": {},
   "source": [
    "<h4>Comandos SQL de criação das tabelas</h4>\n",
    "\n",
    "```sql\n",
    "-- Dimensão Cliente\n",
    "CREATE TABLE [dbo].[Dim_Clientes]\n",
    "(\n",
    "\t[Cod_Cliente_Pedido] CHAR(32) NOT NULL,\n",
    "\t[Cod_Cliente] CHAR(32) NULL,\n",
    "\t[Cidade] VARCHAR(50) NULL,\n",
    "\t[Estado] VARCHAR(50) NULL,\n",
    "\t[Latitude] FLOAT NULL,\n",
    "\t[Longitude] FLOAT NULL,\n",
    "\t[Prefix_Cep] CHAR(5) NULL,\n",
    "\tCONSTRAINT PK_CLIENTES PRIMARY KEY CLUSTERED (Cod_Cliente_Pedido)\n",
    ")\n",
    "\n",
    "-- Dimensão Pagamentos\n",
    "CREATE TABLE [dbo].[Dim_Pagamentos]\n",
    "(\n",
    "\t[Cod_Pedido] CHAR(32) NOT NULL,\n",
    "\t[Sequencial_Pagamento] INT NOT NULL,\n",
    "\t[Tipo] VARCHAR(50) NULL,\n",
    "\t[Parcelas] INT NULL,\n",
    "\t[Valor] FLOAT NULL,\n",
    "\tCONSTRAINT PK_PAGAMENTOS PRIMARY KEY CLUSTERED ([Cod_Pedido],[Sequencial_Pagamento])\n",
    ")\n",
    "\n",
    "-- Dimensão Produtos\n",
    "CREATE TABLE [dbo].[Dim_Produtos]\n",
    "(\n",
    "\t[Cod_Produto] CHAR(32) NOT NULL,\n",
    "\t[Categoria] VARCHAR(50) NULL,\n",
    "\t[Tamanho_Nome] INT NULL,\n",
    "\t[Tamanho_Descricao] INT NULL,\n",
    "\t[Qnt_Fotos] INT NULL,\n",
    "\t[Massa] INT NULL,\n",
    "\t[Comprimento] INT NULL,\n",
    "\t[Largura] INT NULL,\n",
    "\t[Altura] INT NULL,\n",
    "\tCONSTRAINT PK_PRODUTOS PRIMARY KEY CLUSTERED (Cod_Produto)\n",
    ")\n",
    "\n",
    "-- Dimensão Tempo\n",
    "CREATE TABLE [dbo].[Dim_Tempo]\n",
    "(\n",
    "\t[Cod_Dia] NVARCHAR(50) NOT NULL, \n",
    "    [Data] DATE NULL, \n",
    "    [Cod_Semana] INT NULL, \n",
    "    [Nome_Dia_Semana] NVARCHAR(50) NULL, \n",
    "    [Cod_Mes] INT NULL, \n",
    "    [Nome_Mes] NVARCHAR(50) NULL, \n",
    "    [Cod_Mes_Ano] NVARCHAR(50) NULL, \n",
    "    [Nome_Mes_ano] NVARCHAR(50) NULL, \n",
    "    [Cod_Trimestre] INT NULL, \n",
    "    [Nome_Trimestre] NVARCHAR(50) NULL, \n",
    "    [Cod_Trimestre_Ano] NVARCHAR(50) NULL, \n",
    "    [Nome_Trimestre_Ano] NVARCHAR(50) NULL, \n",
    "    [Cod_Semestre] INT NULL, \n",
    "    [Nome_Semestre] NVARCHAR(50) NULL, \n",
    "    [Cod_Semestre_Ano] NVARCHAR(50) NULL, \n",
    "    [Nome_Semestre_Ano] NVARCHAR(50) NULL, \n",
    "    [Ano] NVARCHAR(50) NULL, \n",
    "    [Tipo_Dia] NVARCHAR(50) NULL,\n",
    "    CONSTRAINT PK_TEMPO PRIMARY KEY CLUSTERED ([Cod_Dia])\n",
    ")\n",
    "\n",
    "-- Dimensão Vendedores\n",
    "CREATE TABLE [dbo].[Dim_Vendedores]\n",
    "(\n",
    "\t[Cod_Vendedor] CHAR(32) NOT NULL,\n",
    "\t[Cidade] VARCHAR(50) NULL,\n",
    "\t[Estado] VARCHAR(50) NULL,\n",
    "\t[Latitude] FLOAT NULL,\n",
    "\t[Longitude] FLOAT NULL,\n",
    "\t[Prefix_Cep] CHAR(5) NULL,\n",
    "\tCONSTRAINT PK_VENDEDORES PRIMARY KEY CLUSTERED (Cod_Vendedor)\n",
    ")\n",
    "\n",
    "-- Fato Itens Pedido\n",
    "CREATE TABLE [dbo].[Fato_Itens_Pedido]\n",
    "(\n",
    "\t[Cod_Pedido] CHAR(32) NOT NULL,\n",
    "\t[Sequencial_Pagamento] INT NOT NULL,\n",
    "\t[Item_Pedido] INT NOT NULL,\n",
    "\t[Prefix_Cep] CHAR(5) NULL,\n",
    "\t[Cod_Data_Pedido] NVARCHAR(50) NULL,\n",
    "\t[Hora_Pedido] TIME NULL,\n",
    "\t[Cod_Data_Aprovacao] NVARCHAR(50) NULL,\n",
    "\t[Hora_Aprovacao] TIME NULL,\n",
    "\t[Cod_Data_Entrega_Transportadora] NVARCHAR(50) NULL,\n",
    "\t[Hora_Entrega_Transportadora] TIME NULL,\n",
    "\t[Cod_Data_Entrega_Cliente] NVARCHAR(50) NULL,\n",
    "\t[Hora_Entrega_Cliente] TIME NULL,\n",
    "\t[Cod_Data_Estimada_Entrega] NVARCHAR(50) NULL,\n",
    "\t[Status_Entrega] NVARCHAR(50) NULL,\n",
    "\t[Preco] FLOAT NULL,\n",
    "\t[Frete] FLOAT NULL,\n",
    "\t[Cod_Cliente] CHAR(32) NOT NULL,\n",
    "\t[Cod_Vendedor] CHAR(32) NOT NULL,\n",
    "\t[Cod_Produto] CHAR(32) NOT NULL,\n",
    "\tCONSTRAINT PK_FATO_ITENS_PEDIDO PRIMARY KEY CLUSTERED ([Cod_Pedido],[Item_Pedido],[Cod_Cliente],[Cod_Vendedor],[Cod_Produto],[Sequencial_Pagamento]), \n",
    "    CONSTRAINT [FK_Fato_Itens_Pedido_Dim_Cliente] FOREIGN KEY ([Cod_Cliente]) REFERENCES [Dim_Clientes]([Cod_Cliente_Pedido]), \n",
    "    CONSTRAINT [FK_Fato_Itens_Pedido_Dim_Produtos] FOREIGN KEY ([Cod_Produto]) REFERENCES [Dim_Produtos]([Cod_Produto]),\n",
    "\tCONSTRAINT [FK_Fato_Itens_Pedido_Dim_Pagamentos] FOREIGN KEY ([Cod_Pedido],[Sequencial_Pagamento]) REFERENCES [Dim_Pagamentos]([Cod_Pedido],[Sequencial_Pagamento]),\n",
    "    CONSTRAINT [FK_Fato_Itens_Pedido_Dim_Vendedores] FOREIGN KEY ([Cod_Vendedor]) REFERENCES [Dim_Vendedores]([Cod_Vendedor]), \n",
    "    CONSTRAINT [FK_Fato_Itens_Pedido_Dim_Tempo] FOREIGN KEY ([Cod_Data_Pedido]) REFERENCES [Dim_Tempo]([Cod_Dia]),\n",
    ")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c826e0de",
   "metadata": {},
   "source": [
    "<h3>Carga das tabelas</h3>\n",
    "\n",
    "<table>\n",
    "    <td><img src=\"screenshots/10.jpg\" width=\"200\"/></td>\n",
    "    <td><img src=\"screenshots/11.jpg\" width=\"200\"/></td>\n",
    "    <td><img src=\"screenshots/12.jpg\" width=\"200\"/></td>\n",
    "</table>\n",
    "    \n",
    "<td><img src=\"screenshots/13.jpg\" width=\"350\"/></td>\n",
    "    \n",
    "<p>\n",
    "    Para a carga dos dados nas tabelas se faz necessária a criação de um projeto do Integration Service dentro do Visual Studio. Clicando com o botão direito do mouse na solução do VS, cria-se o projeto conforme as imagens acima.\n",
    "</p>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td colspan=\"3\"><img src=\"screenshots/15.jpg\" width=\"600\"/></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"screenshots/14.jpg\" width=\"150\"/></td>\n",
    "        <td><img src=\"screenshots/16.jpg\" width=\"200\"/></td>\n",
    "        <td><img src=\"screenshots/17.jpg\" width=\"400\"/></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<p>\n",
    "    No lado esquerdo do layout do Visual Studio ficam dispostas todas as ferramentas para a construção do ETL. No caso da carga, é necessário começar com um objeto de fluxo de dados, que habilita uma nova aba de fluxo de dados. Nesta nova aba inseri-se um assistente de origem dos dados, que pode ser um arquivo excel, flat file ou até uma conexão com um banco de dados. No caso, estabeleceu-se uma conexão com um banco de dados on premise SQL Server.\n",
    "</p>\n",
    "\n",
    "<table>\n",
    "    <td><img src=\"screenshots/18.jpg\" width=\"400\"/></td>\n",
    "    <td><img src=\"screenshots/19.jpg\" width=\"400\"/></td>\n",
    "</table>\n",
    "\n",
    "<p>\n",
    "    Conforme a primeira imagem acima, se estabelece uma conexão com o banco de dados. Neste projeto optou-se pelo uso de consultas SQL para organizar as tabelas conforme a modelagem dimensional. Os comandos utilizados podem ser verificados na próxima sessão do artigo.\n",
    "</p>\n",
    "\n",
    "<table>\n",
    "    <td><img src=\"screenshots/20.jpg\" width=\"200\"/></td>\n",
    "    <td><img src=\"screenshots/21.jpg\" width=\"400\"/></td>\n",
    "    <td><img src=\"screenshots/22.jpg\" width=\"400\"/></td>\n",
    "</table>\n",
    "\n",
    "<p>\n",
    "    Optou-se pela ferramenta dimensão de alteração lenta para a carga dos dados pois permite a modificação de registro já existentes e impede erros de duplicação de chave primária. Esta ferramenta verifica os registros e, utilizando como parâmetro a chave primária da tabela (business key), possibilita a alteração de algum campo do registro.\n",
    "</p>\n",
    "\n",
    "<table>\n",
    "    <td><img src=\"screenshots/24.jpg\" width=\"400\"/></td>\n",
    "    <td><img src=\"screenshots/25.jpg\" width=\"400\"/></td>\n",
    "</table>\n",
    "\n",
    "<p>\n",
    "    Para configurar a tabela destino dos dados, seleciona-se a conexão anteriormente estabelecida com o banco de dados da tabela a ser carregada. É importante se atentar ao mapeamento feito automaticamente dos campos da tabela origem para a tabela destino.\n",
    "</p>\n",
    "\n",
    "<table>\n",
    "    <tr><img src=\"screenshots/23.jpg\" width=\"500\"/></tr>\n",
    "    <tr><img src=\"screenshots/26.jpg\" width=\"500\"/></tr>\n",
    "</table>\n",
    "\n",
    "<p>\n",
    "    Uma vez o fluxo criado, recompilamos o pacote de carga e, não havendo nenhum erro, selecionamos o play na barra de ferramentas no topo da tela.\n",
    "</p>\n",
    "\n",
    "<table>\n",
    "    <td><img src=\"screenshots/27.1.jpg\" width=\"500\"/></td>\n",
    "    <td><img src=\"screenshots/28.jpg\" width=\"350\"/></td>\n",
    "</table>\n",
    "\n",
    "<p>   \n",
    "    Após a criação do fluxo de carregamento dos dados para cada uma das dimensões, podemos atrelar cada um destes fluxos de maneira que quando haja uma alteração de dados em alguma das dimensões, todo o processo de ETL seja novamente executado. Note que existe a separação em dois fluxos de carregamento, um para a tabelas de dimensões e outra para a tabela fato. Caso existi-se uma outra tabela fato no projeto, esta estaria no mesmo fluxo de dados da primeira.\n",
    "</p>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"screenshots/29.jpg\" width=\"250\"/></td>\n",
    "        <td><img src=\"screenshots/30.jpg\" width=\"200\"/></td>\n",
    "        <td><img src=\"screenshots/31.jpg\" width=\"500\"/></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td colspan=\"3\"><img src=\"screenshots/32.jpg\" width=\"400\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "<p>\n",
    "    Para automatizar o processo por completo, cria-se um novo pacote de carregamento que executa em série os pacotes de carregamento das dimensões e da tabela fato conforme imagem acima.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c492b1",
   "metadata": {},
   "source": [
    "<h4>Consultas SQL para a carga do data warehouse</h4>\n",
    "\n",
    "```sql\n",
    "-- Fato Itens Pedido\n",
    "SELECT\n",
    "\tped.cod_pedido\n",
    "\t,pag.sequencial_pagamento\n",
    "\t,it.item_pedido\n",
    "\t,geo.prefix_cep\n",
    "\t,FORMAT(ped.data,'yyyyMMdd') AS cod_data_pedido\n",
    "\t,CAST(ped.data AS TIME(0)) AS hora_pedido\n",
    "\t,FORMAT(ped.data_aprovacao,'yyyyMMdd') AS cod_data_aprovacao\n",
    "\t,CAST(ped.data_aprovacao AS TIME(0)) AS hora_aprovacao\n",
    "\t,FORMAT(ped.data_entrega_transportadora,'yyyyMMdd' ) AS cod_data_entrega_transportadora\n",
    "\t,CAST(ped.data_entrega_transportadora AS TIME(0)) AS hora_entrega_transportadora\n",
    "\t,FORMAT(ped.data_entrega_cliente,'yyyyMMdd') AS cod_data_entrega_cliente\n",
    "\t,CAST(ped.data_entrega_cliente AS TIME(0)) AS hora_entrega_cliente\n",
    "\t,FORMAT(ped.data_estimada_entrega, 'yyyyMMdd') AS cod_data_estimada_entrega\n",
    "\t,ped.status\n",
    "\t,CASE WHEN pag.sequencial_pagamento = 1 THEN it.preco ELSE 0 END AS valor_item_pedido\n",
    "\t,CASE WHEN pag.sequencial_pagamento = 1 THEN it.frete ELSE 0 END AS frete_item_pedido\n",
    "\t,ped.cod_cliente\n",
    "\t,it.cod_vendedor\n",
    "\t,prod.cod_produto\n",
    "FROM\n",
    "\tITENS_PEDIDO it\n",
    "LEFT JOIN\n",
    "\tPEDIDOS ped ON ped.cod_pedido = it.cod_pedido\n",
    "LEFT JOIN\n",
    "\tPRODUTOS prod ON prod.cod_produto = it.cod_produto\n",
    "LEFT JOIN\n",
    "\tPAGAMENTOS pag ON pag.cod_pedido = it.cod_pedido\n",
    "LEFT JOIN\n",
    "\t(SELECT c.cod_cliente_pedido, geo.cidade, geo.estado, geo.latitude, geo.longitude, geo.prefix_cep \n",
    "\t FROM \n",
    "\t\tCLIENTES c\n",
    "\t INNER JOIN\t\n",
    "\t\tGEOLOCALIZACAO geo ON c.prefix_cep = geo.prefix_cep) geo ON geo.cod_cliente_pedido = ped.cod_cliente\n",
    "LEFT JOIN\n",
    "\tVENDEDORES vend ON vend.cod_vendedor = it.cod_vendedor\n",
    "\n",
    "-- Dimensão Vendedores\n",
    "SELECT \n",
    "\tvend.cod_vendedor\n",
    "\t,geo.cidade\n",
    "\t,geo.estado\n",
    "\t,geo.latitude\n",
    "\t,geo.longitude\n",
    "\t,geo.prefix_cep\n",
    "FROM \n",
    "\tVENDEDORES vend\n",
    "LEFT JOIN\n",
    "\tGEOLOCALIZACAO geo ON geo.prefix_cep = vend.prefix_cep\n",
    "\n",
    "-- Dimensão Clientes\n",
    "SELECT \n",
    "\tc.cod_cliente_pedido\n",
    "\t,c.cod_cliente\n",
    "\t,geo.cidade\n",
    "\t,geo.estado\n",
    "\t,geo.latitude\n",
    "\t,geo.longitude\n",
    "\t,geo.prefix_cep\n",
    "FROM \n",
    "\tCLIENTES c\n",
    "LEFT JOIN\n",
    "\tGEOLOCALIZACAO geo ON geo.prefix_cep = c.prefix_cep\n",
    "\n",
    "-- Dimensão Produtos\n",
    "SELECT * FROM PRODUTOS\n",
    "\n",
    "-- Dimensão Pagamentos\n",
    "SELECT * FROM PAGAMENTOS\n",
    "\n",
    "-- Dimensão Tempo\n",
    "DECLARE @DIMDATE TABLE\n",
    "\t(\t[Cod_Dia] NVARCHAR(50) primary key, \n",
    "\t\t[Data] DATE,\n",
    "\t\t[Cod_Semana] int,-- 01,02,03 .... 42,43,44\n",
    "\t\t[Nome_Dia_Semana] NVARCHAR(50),-- Segunda, terça, quarta, quinta, sexta\n",
    "\t\t[Cod_Mes] int,-- 01,02,03 ... , 11, 12\n",
    "\t\t[Nome_Mes] NVARCHAR(50),-- Janeiro, Fevereiro, Março, ... Novembro, Dezembro\n",
    "\t\t[Cod_Mes_Ano] NVARCHAR(50),-- 2017-01, 2017-02, ..., 2017-11, 2017-12\n",
    "\t\t[Nome_Mes_Ano] NVARCHAR(50),-- Janeiro 2017, Fevereiro 2017, ....\n",
    "\t\t[Cod_Trimestre] int,-- 01, 02, 03, 04\n",
    "\t\t[Nome_Trimestre] NVARCHAR(50),-- Primeiro Trimestre, Segundo Trimestre, ...\n",
    "\t\t[Cod_Trimestre_Ano] NVARCHAR(50),-- 2017-01, 2017-02, ...\n",
    "\t\t[Nome_Trimestre_Ano] NVARCHAR(50),-- Primeiro Trimestre 2017, Segundo Trimestre 2017, ...\n",
    "\t\t[Cod_Semestre] int,-- 01, 02, ...\n",
    "\t\t[Nome_Semestre] NVARCHAR(50),-- Primeiro Semestre, Segundo Semestre, ...\n",
    "\t\t[Cod_Semestre_Ano] NVARCHAR(50),-- 2017-01, 2017-02, ...\n",
    "\t\t[Nome_Semestre_Ano] NVARCHAR(50),-- Primeiro Semestre, Segundo Semestre, ...\n",
    "\t\t[Ano] NVARCHAR(50),-- 2017, ...\n",
    "\t\t[Tipo_Dia] NVARCHAR(50) -- Dia Útil ou Fim de Semana\n",
    "\t)\n",
    "\n",
    "DECLARE @AnoInicial VARCHAR(4) = '2016'\n",
    "DECLARE @MesInicial VARCHAR(2) = '1'\n",
    "DECLARE @AnoFinal VARCHAR(4) = '2018'\n",
    "DECLARE @MesFinal VARCHAR(2) = '12'\n",
    "\n",
    "DECLARE @StartDate DATETIME\n",
    "Select @StartDate = CAST(@AnoInicial + '/' + @MesInicial + '/01' AS DATETIME)\n",
    "\n",
    "DECLARE @EndDate DATETIME \n",
    "SELECT @EndDate = DATEADD(month, ((CAST(@AnoFinal AS INTEGER) - 1900) * 12) + CAST(@MesFinal AS INTEGER), 0)\n",
    "\n",
    "-- Variáveis temporárias para guardar valores durante o processo de cada ano.\n",
    "DECLARE\n",
    "\t@DayOfWeekInMonth INT,\n",
    "\t@DayOfWeekInYear INT,\n",
    "\t@DayOfQuarter INT,\n",
    "\t@WeekOfMonth INT,\n",
    "\t@CurrentYear INT,\n",
    "\t@CurrentMonth INT,\n",
    "\t@CurrentQuarter INT\n",
    "\n",
    "/*Tabela para armazenar o dia da semana para o mês e ano*/\n",
    "DECLARE @DayOfWeek TABLE (DOW INT, MonthCount INT, QuarterCount INT, YearCount INT)\n",
    "\n",
    "INSERT INTO @DayOfWeek VALUES (1, 0, 0, 0)\n",
    "INSERT INTO @DayOfWeek VALUES (2, 0, 0, 0)\n",
    "INSERT INTO @DayOfWeek VALUES (3, 0, 0, 0)\n",
    "INSERT INTO @DayOfWeek VALUES (4, 0, 0, 0)\n",
    "INSERT INTO @DayOfWeek VALUES (5, 0, 0, 0)\n",
    "INSERT INTO @DayOfWeek VALUES (6, 0, 0, 0)\n",
    "INSERT INTO @DayOfWeek VALUES (7, 0, 0, 0)\n",
    "\n",
    "--Extrai e designa a parte da data para a variável\n",
    "\n",
    "DECLARE @CurrentDate AS DATETIME = @StartDate\n",
    "SET @CurrentMonth = DATEPART(MM, @CurrentDate)\n",
    "SET @CurrentYear = DATEPART(YY, @CurrentDate)\n",
    "SET @CurrentQuarter = DATEPART(QQ, @CurrentDate)\n",
    "\n",
    "--Checagem de data atual menor que a data final especificado acima\n",
    "\n",
    "WHILE @CurrentDate < @EndDate\n",
    "BEGIN\n",
    " \n",
    "/*Começo da lógica dia da semana*/\n",
    "\n",
    "         /*Checagem da mudança de mês para a data atual, se o mês muda, muda-se o valor da variável*/\n",
    "\tIF @CurrentMonth != DATEPART(MM, @CurrentDate) \n",
    "\tBEGIN\n",
    "\t\tUPDATE @DayOfWeek\n",
    "\t\tSET MonthCount = 0\n",
    "\t\tSET @CurrentMonth = DATEPART(MM, @CurrentDate)\n",
    "\tEND\n",
    "\n",
    "        /* Checagem de mudança de trimestre*/\n",
    "\n",
    "\tIF @CurrentQuarter != DATEPART(QQ, @CurrentDate)\n",
    "\tBEGIN\n",
    "\t\tUPDATE @DayOfWeek\n",
    "\t\tSET QuarterCount = 0\n",
    "\t\tSET @CurrentQuarter = DATEPART(QQ, @CurrentDate)\n",
    "\tEND\n",
    "       \n",
    "        /* Checagem de mudança de ano*/\n",
    "\t\n",
    "\n",
    "\tIF @CurrentYear != DATEPART(YY, @CurrentDate)\n",
    "\tBEGIN\n",
    "\t\tUPDATE @DayOfWeek\n",
    "\t\tSET YearCount = 0\n",
    "\t\tSET @CurrentYear = DATEPART(YY, @CurrentDate)\n",
    "\tEND\n",
    "\t\n",
    "        -- Atribui valores conforme as variáveis acima \n",
    "\n",
    "\tUPDATE @DayOfWeek\n",
    "\tSET \n",
    "\t\tMonthCount = MonthCount + 1,\n",
    "\t\tQuarterCount = QuarterCount + 1,\n",
    "\t\tYearCount = YearCount + 1\n",
    "\tWHERE DOW = DATEPART(DW, @CurrentDate)\n",
    "\n",
    "\tSELECT\n",
    "\t\t@DayOfWeekInMonth = MonthCount,\n",
    "\t\t@DayOfQuarter = QuarterCount,\n",
    "\t\t@DayOfWeekInYear = YearCount\n",
    "\tFROM @DayOfWeek\n",
    "\tWHERE DOW = DATEPART(DW, @CurrentDate)\n",
    "\t\n",
    "/*Fim da lógica dia da semana*/\n",
    "\n",
    "/* Insere valores na tabela*/\n",
    "\t\n",
    "\tINSERT INTO @DIMDATE\n",
    "\tSELECT\t\n",
    "\t\tCONVERT (NVARCHAR(8),@CurrentDate,112) as Cod_Dia,\n",
    "\t\t@CurrentDate as Data,\n",
    "\t\tRIGHT ('00'+LTRIM(STR(CONVERT(NVARCHAR(2), @DayOfWeekInYear))),2 ) as Cod_Semana,\n",
    "\t\tCASE DATEPART(DW, @CurrentDate)\n",
    "\t\t\tWHEN 1 THEN 'Domingo'\n",
    "\t\t\tWHEN 2 THEN 'Segunda'\n",
    "\t\t\tWHEN 3 THEN 'Terça'\n",
    "\t\t\tWHEN 4 THEN 'Quarta'\n",
    "\t\t\tWHEN 5 THEN 'Quinta'\n",
    "\t\t\tWHEN 6 THEN 'Sexta'\n",
    "\t\t\tWHEN 7 THEN 'Sábado'\n",
    "\t\t\tEND \n",
    "\t\t\tAS D_Nome_Dia_Semana,\n",
    "        RIGHT ('00'+LTRIM(STR(CONVERT(NVARCHAR(2), DATEPART(MM, @CurrentDate)))),2 )  as Cod_Mes,\n",
    "\t\tCASE DATEPART(MM, @CurrentDate)\n",
    "\t\t\tWHEN 1 THEN 'Janeiro'\n",
    "\t\t\tWHEN 2 THEN 'Fevereiro'\n",
    "\t\t\tWHEN 3 THEN 'Março'\n",
    "\t\t\tWHEN 4 THEN 'Abril'\n",
    "\t\t\tWHEN 5 THEN 'Maio'\n",
    "\t\t\tWHEN 6 THEN 'Junho'\n",
    "\t\t\tWHEN 7 THEN 'Julho'\n",
    "\t\t\tWHEN 8 THEN 'Agosto'\n",
    "\t\t\tWHEN 9 THEN 'Setembro'\n",
    "\t\t\tWHEN 10 THEN 'Outubro'\n",
    "\t\t\tWHEN 11 THEN 'Novembro'\n",
    "\t\t\tWHEN 12 THEN 'Dezembro'\n",
    "\t\t\tEND \n",
    "\t\t\tAS D_Nome_Mes,\n",
    "\t\t\tRIGHT ('00'+LTRIM(STR(CONVERT(NVARCHAR(2), DATEPART(MM, @CurrentDate)))),2 ) + '-' + CONVERT(NVARCHAR(4), DATEPART(YEAR, @CurrentDate)) as Cod_Mes_Ano,\n",
    "\t\t\tCASE DATEPART(MM, @CurrentDate)\n",
    "\t\t\tWHEN 1 THEN 'Janeiro'\n",
    "\t\t\tWHEN 2 THEN 'Fevereiro'\n",
    "\t\t\tWHEN 3 THEN 'Março'\n",
    "\t\t\tWHEN 4 THEN 'Abril'\n",
    "\t\t\tWHEN 5 THEN 'Maio'\n",
    "\t\t\tWHEN 6 THEN 'Junho'\n",
    "\t\t\tWHEN 7 THEN 'Julho'\n",
    "\t\t\tWHEN 8 THEN 'Agosto'\n",
    "\t\t\tWHEN 9 THEN 'Setembro'\n",
    "\t\t\tWHEN 10 THEN 'Outubro'\n",
    "\t\t\tWHEN 11 THEN 'Novembro'\n",
    "\t\t\tWHEN 12 THEN 'Dezembro'\n",
    "\t\t\tEND + ' ' + CONVERT(NVARCHAR(4), DATEPART(YEAR, @CurrentDate)) as D_Nome_Mes_Ano,\n",
    "\t\t\tRIGHT ('00'+LTRIM(STR(CONVERT(NVARCHAR(2), DATEPART(QQ, @CurrentDate)))),2 ) AS Cod_Trimestre,\n",
    "\t\t\tCASE DATEPART(QQ, @CurrentDate)\n",
    "\t\t\tWHEN 1 THEN 'Primeiro Trimestre'\n",
    "\t\t\tWHEN 2 THEN 'Segundo Trimestre'\n",
    "\t\t\tWHEN 3 THEN 'Terceiro Trimestre'\n",
    "\t\t\tWHEN 4 THEN 'Quarto Trimestre'\n",
    "\t\t\tEND AS D_Nome_Trimestre,\n",
    "\t\t\tRIGHT ('00'+LTRIM(STR(CONVERT(NVARCHAR(2), DATEPART(QQ, @CurrentDate)))),2 ) + '-' + \n",
    "\t\t\tCONVERT(NVARCHAR(4), DATEPART(YEAR, @CurrentDate)) as Cod_Trimestre_Ano,\n",
    "\t\t\tCASE DATEPART(QQ, @CurrentDate)\n",
    "\t\t\tWHEN 1 THEN 'Primeiro Trimestre'\n",
    "\t\t\tWHEN 2 THEN 'Segundo Trimestre'\n",
    "\t\t\tWHEN 3 THEN 'Terceiro Trimestre'\n",
    "\t\t\tWHEN 4 THEN 'Quarto Trimestre'\n",
    "\t\t\tEND + ' ' + CONVERT(NVARCHAR(4), DATEPART(YEAR, @CurrentDate)) AS D_Nome_Trimestre_Ano,\n",
    "\t\t\tCASE DATEPART(QQ, @CurrentDate)\n",
    "\t\t\tWHEN 1 THEN '01'\n",
    "\t\t\tWHEN 2 THEN '01'\n",
    "\t\t\tWHEN 3 THEN '02'\n",
    "\t\t\tWHEN 4 THEN '02'\n",
    "\t\t\tEND \n",
    "\t\t\tAS Cod_Semestre,\n",
    "\t\t\tCASE DATEPART(QQ, @CurrentDate)\n",
    "\t\t\tWHEN 1 THEN 'Primeiro Semestre'\n",
    "\t\t\tWHEN 2 THEN 'Primeiro Semestre'\n",
    "\t\t\tWHEN 3 THEN 'Segundo Semestre'\n",
    "\t\t\tWHEN 4 THEN 'Segundo Semestre'\n",
    "\t\t\tEND \n",
    "\t\t\tAS D_Nome_Semestre,\n",
    "\t\t\tCASE DATEPART(QQ, @CurrentDate)\n",
    "\t\t\tWHEN 1 THEN '01'\n",
    "\t\t\tWHEN 2 THEN '01'\n",
    "\t\t\tWHEN 3 THEN '02'\n",
    "\t\t\tWHEN 4 THEN '02'\n",
    "\t\t\tEND + '-' + \n",
    "\t\t\tCONVERT(NVARCHAR(4), DATEPART(YEAR, @CurrentDate)) as Cod_Semestre_Ano,\n",
    "\t\t\tCASE DATEPART(QQ, @CurrentDate)\n",
    "\t\t\tWHEN 1 THEN 'Primeiro Semestre'\n",
    "\t\t\tWHEN 2 THEN 'Primeiro Semestre'\n",
    "\t\t\tWHEN 3 THEN 'Segundo Semestre'\n",
    "\t\t\tWHEN 4 THEN 'Segundo Semestre'\n",
    "\t\t\tEND + ' ' + \n",
    "\t\t\tCONVERT(NVARCHAR(4), DATEPART(YEAR, @CurrentDate)) as D_Nome_Semestre_Ano,\n",
    "\t\t\tCONVERT(NVARCHAR(4), DATEPART(YEAR, @CurrentDate)) AS Ano,\n",
    "\t\t\tCASE DATEPART(DW, @CurrentDate)\n",
    "\t\t\tWHEN 1 THEN 'Fim de Semana'\n",
    "\t\t\tWHEN 2 THEN 'Dia Útil'\n",
    "\t\t\tWHEN 3 THEN 'Dia Útil'\n",
    "\t\t\tWHEN 4 THEN 'Dia Útil'\n",
    "\t\t\tWHEN 5 THEN 'Dia Útil'\n",
    "\t\t\tWHEN 6 THEN 'Dia Útil'\n",
    "\t\t\tWHEN 7 THEN 'Fim de Semana'\n",
    "\t\t\tEND \n",
    "\t\t\tAS Tipo_Dia\n",
    "\n",
    "\tSET @CurrentDate = DATEADD(DD, 1, @CurrentDate)\n",
    "END\n",
    "\n",
    "SELECT * FROM @DIMDATE order by Cod_Dia\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5357818c",
   "metadata": {},
   "source": [
    "<h3>Modelo de dados Multidimensional</h3>\n",
    "\n",
    "<img src=\"screenshots/modelo_dimensional.jpg\" width=\"700\">   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d553174e",
   "metadata": {},
   "source": [
    "<h2>Comparações</h2>\n",
    "\n",
    "<p>\n",
    "    As consultas abaixo retornam a quantidade de unidades vendidas por categoria de produto para o estado de São Paulo.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2360081",
   "metadata": {},
   "source": [
    "```sql\n",
    "-- Modelo Multidimensional\n",
    "SELECT \n",
    "  prod.Categoria\n",
    "  ,COUNT(*) AS Unidades_vendidas \n",
    "FROM \n",
    "  [DW_OLIST].[dbo].[Fato_Itens_Pedido] itp \n",
    "  INNER JOIN [DW_OLIST].[dbo].[Dim_Produtos] prod ON prod.Cod_Produto = itp.Cod_Produto \n",
    "  INNER JOIN [DW_OLIST].[dbo].[Dim_Clientes] cli ON cli.Cod_Cliente_Pedido = itp.Cod_Cliente \n",
    "WHERE \n",
    "  cli.Estado = 'sp' \n",
    "GROUP BY \n",
    "  prod.Categoria \n",
    "ORDER BY \n",
    "  COUNT(*) DESC;\n",
    "```  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebc04e1",
   "metadata": {},
   "source": [
    "<p>\n",
    "    Podemos perceber que no modelo multidimensional as consultas são mais simples pois só existe relacionamento entre tabela fato e dimensão. Isto pode trazer um ganho na performance das consultas e alimentação de pipeline de modelos de data science quando tratamos de grandes volumes de dados. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3872165b",
   "metadata": {},
   "source": [
    "```sql\n",
    "-- Modelo Relacional\n",
    "SELECT \n",
    "  it_pr_ped.categoria\n",
    "  ,COUNT(*) AS Unidades_vendidas\n",
    "FROM \n",
    "  [RELACIONAL_OLIST].[dbo].[CLIENTES] cli \n",
    "  RIGHT JOIN (\n",
    "    SELECT \n",
    "      it_prod.cod_produto, \n",
    "      ped.cod_pedido, \n",
    "      ped.cod_cliente, \n",
    "      ped.data, \n",
    "      it_prod.categoria, \n",
    "      it_prod.item_pedido, \n",
    "      it_prod.preco, \n",
    "      it_prod.frete \n",
    "    FROM \n",
    "      [RELACIONAL_OLIST].[dbo].[PEDIDOS] ped \n",
    "      RIGHT JOIN(\n",
    "        SELECT \n",
    "          prod.categoria, \n",
    "          prod.cod_produto, \n",
    "          itns.item_pedido, \n",
    "          itns.cod_pedido, \n",
    "          itns.preco, \n",
    "          itns.frete \n",
    "        FROM\n",
    "\t\t  [RELACIONAL_OLIST].[dbo].[ITENS_PEDIDO] itns\n",
    "          LEFT JOIN [RELACIONAL_OLIST].[dbo].[PRODUTOS] prod ON prod.cod_produto = itns.cod_produto\n",
    "      ) it_prod ON ped.cod_pedido = it_prod.cod_pedido\n",
    "  ) it_pr_ped ON it_pr_ped.cod_cliente = cli.cod_cliente_pedido\n",
    "WHERE \n",
    "\tcli.estado = 'SP'\n",
    "GROUP BY \n",
    "\tit_pr_ped.categoria\n",
    "ORDER BY \n",
    "\tCOUNT(*) DESC;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91282bd9",
   "metadata": {},
   "source": [
    "<p>\n",
    "    Já no modelo relacional temos que executar mais junções entre tabelas para obtermos o mesmo resultado devido a sua complexidade, isto também pode dificultar a integridade dos dados conforme escalamos o banco para gerir grandes volumes de dados.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985ea309",
   "metadata": {},
   "source": [
    "<h2>Próximos passos</h2>\n",
    "\n",
    "<p>\n",
    "    A partir do banco de dados multidimensional será construido um banco OLAP (Online Analytical Processing) para alimentar uma fictícia área de negócios com indicadores propostos. Na sequencial será desenvolvido dashboards concluindo todo o pipeline de extração dos dados crus até a entrega de visualizações que ajudarão na tomada de decisões da área de negócios.\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
